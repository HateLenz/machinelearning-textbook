{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T11:37:42.062330Z",
     "start_time": "2024-04-07T11:37:42.042381Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8859476187202091\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义激活函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 定义一个简单的神经元\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "# 权重和偏置\n",
    "weights = np.array([0.2, -0.5])\n",
    "bias = 2\n",
    "\n",
    "# 创建神经元实例\n",
    "neuron = Neuron(weights, bias)\n",
    "\n",
    "# 输入向量\n",
    "inputs = np.array([0.5, 0.1])\n",
    "\n",
    "# 前向传播\n",
    "output = neuron.feedforward(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f093a2af820e1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "简单神经元模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc93a6f75f347d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T13:29:17.627624Z",
     "start_time": "2024-04-07T13:29:17.584739Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron predictions for AND operation:\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 0\n",
      "[1 1] -> 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)\n",
    "           \n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        return 1 if summation > 0 else 0\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Define training data for AND operation\n",
    "    training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    labels = np.array([0, 0, 0, 1])  # AND operation labels\n",
    "\n",
    "    # Create a Perceptron instance with 2 inputs\n",
    "    perceptron = Perceptron(no_of_inputs=2)\n",
    "    \n",
    "    # Train the perceptron\n",
    "    perceptron.train(training_inputs, labels)\n",
    "\n",
    "    # Test the perceptron to make predictions\n",
    "    print(\"Perceptron predictions for AND operation:\")\n",
    "    for input_data in training_inputs:\n",
    "        print(f\"{input_data} -> {perceptron.predict(input_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994a2eb9f89103",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "单层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de2793dd5a86063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T02:57:35.105760Z",
     "start_time": "2024-04-09T02:57:35.079800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.14500000000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_true = np.array([1, 2, 3, 4])\n",
    "y_pred = np.array([1.5, 2.5, 2.8, 4.2])\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算均方误差(MSE)\n",
    "    :param y_true: 真实值\n",
    "    :param y_pred: 预测值\n",
    "    :return: MSE损失值\n",
    "    \"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546021ccb08e9a59",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "均方误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ad0dbcc25de70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T02:58:59.507989Z",
     "start_time": "2024-04-09T02:58:59.476047Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: 0.356674943938731\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Example usage:\n",
    "# 假设有3个类别，真实值是第二类（索引为1），而模型对每个类别的预测概率为[0.1, 0.7, 0.2]\n",
    "y_true = np.array([0, 1, 0])  # one-hot编码，表示第二类\n",
    "y_pred = np.array([0.1, 0.7, 0.2])  # 模型的预测概率分布\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算交叉熵损失\n",
    "    :param y_true: 真实值的one-hot编码\n",
    "    :param y_pred: 预测值的概率分布\n",
    "    :return: 交叉熵损失值\n",
    "    \"\"\"\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-15))\n",
    "ce_loss = cross_entropy(y_true, y_pred)\n",
    "print(\"Cross Entropy Loss:\", ce_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b4c08db139d9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723365dd4b5dc96b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T04:25:25.580366Z",
     "start_time": "2024-04-09T04:25:25.510555Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross Entropy Loss: 0.22944289410146418\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 假设有5个样本，真实值为[1, 0, 1, 0, 1]，预测值为[0.9, 0.1, 0.8, 0.3, 0.7]\n",
    "y_true = np.array([1, 0, 1, 0, 1])\n",
    "y_pred = np.array([0.9, 0.1, 0.8, 0.3, 0.7])\n",
    "# 定义函数\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算二元交叉熵损失\n",
    "    :param y_true: 真实值\n",
    "    :param y_pred: 预测值\n",
    "    :return: 二元交叉熵损失值\n",
    "    \"\"\"\n",
    "    return -np.mean(y_true * np.log(y_pred + 1e-15) + (1 - y_true) * np.log(1 - y_pred + 1e-15))\n",
    "# 计算二元交叉熵损失\n",
    "loss = binary_cross_entropy(y_true, y_pred)\n",
    "print(\"Binary Cross Entropy Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ded5e451e3cfe18",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "二元交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43c62ab5585f32f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T04:27:09.389078Z",
     "start_time": "2024-04-09T04:27:09.355168Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood Loss: 0.356674943938731\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_true = np.array([0, 1, 0]) \n",
    "y_pred = np.array([0.1, 0.7, 0.2])\n",
    "def log_likelihood(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算对数似然损失\n",
    "    :param y_true: 真实值的one-hot编码\n",
    "    :param y_pred: 预测值的概率分布\n",
    "    :return: 对数似然损失值\n",
    "    \"\"\"\n",
    "    # 计算对数似然损失\n",
    "    loss = -np.sum(y_true * np.log(y_pred + 1e-15))\n",
    "    return loss\n",
    "likelihood_loss = log_likelihood(y_true, y_pred)\n",
    "print(\"Log Likelihood Loss:\", likelihood_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ffb0406c25c790",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "对数似然"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ff45ca6737a9de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T06:48:34.681458Z",
     "start_time": "2024-04-09T06:48:33.355308Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss: 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_true = np.array([1, -1, 1, -1, 1])\n",
    "y_pred = np.array([0.5, -0.3, 0.8, -0.7, 0.2])\n",
    "def hinge_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算Hinge损失\n",
    "    :param y_true: 真实值 (1或-1)\n",
    "    :param y_pred: 预测值\n",
    "    :return: Hinge损失值\n",
    "    \"\"\"\n",
    "    loss = np.maximum(0, 1 - y_true * y_pred)\n",
    "    return np.mean(loss)\n",
    "hinge_loss_value = hinge_loss(y_true, y_pred)\n",
    "print(\"Hinge Loss:\", hinge_loss_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a2793574ff43e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Hinge损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "422901a5d395ec5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T06:20:38.849015Z",
     "start_time": "2024-04-10T06:20:38.814996Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the neural network: [[0.6902096]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "# 输入数据\n",
    "X = np.array([0.1, 0.2])\n",
    "# 权重和偏置\n",
    "W1 = np.array([[0.1, 0.2], [0.3, 0.4]])\n",
    "b1 = np.array([0.1, 0.1])\n",
    "W2 = np.array([[0.5, 0.6]])\n",
    "b2 = np.array([0.2])\n",
    "# 前向传播过程\n",
    "# 隐藏层计算\n",
    "Z1 = np.dot(X, W1) + b1\n",
    "A1 = sigmoid(Z1)  # 激活函数\n",
    "# 将A1的形状从(2,)改变为(1, 2)\n",
    "A1 = A1.reshape(1, -1)\n",
    "# 输出层计算\n",
    "Z2 = np.dot(A1, W2.T) + b2  \n",
    "output = sigmoid(Z2)  #\n",
    "print(\"Output of the neural network:\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d5dba88731173",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898edbbf024d752b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T06:25:04.551341Z",
     "start_time": "2024-04-10T06:25:04.522416Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of W2: [[-0.01273302]\n",
      " [-0.01290758]]\n",
      "Gradient of b2: [-0.02347542]\n",
      "Gradient of W1: [[-0.00029133 -0.00034863]\n",
      " [-0.00058267 -0.00069727]]\n",
      "Gradient of b1: [-0.00291333 -0.00348633]\n"
     ]
    }
   ],
   "source": [
    "# 定义损失函数\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "# 实际输出\n",
    "y_true = 0.8\n",
    "# 计算输出层的误差\n",
    "delta_output = (output - y_true) * output * (1 - output)  # 输出层误差\n",
    "# 计算隐藏层的误差\n",
    "delta_hidden = np.dot(delta_output, W2) * A1 * (1 - A1)  # 隐藏层误差\n",
    "# 计算参数的梯度\n",
    "dW2 = np.dot(A1.T, delta_output)  # 输出层权重的梯度\n",
    "db2 = np.sum(delta_output, axis=0)  # 输出层偏置项的梯度\n",
    "dW1 = np.dot(X.reshape(-1, 1), delta_hidden)  # 隐藏层权重的梯度\n",
    "db1 = np.sum(delta_hidden, axis=0)  # 隐藏层偏置项的梯度\n",
    "\n",
    "# 打印参数的梯度\n",
    "print(\"Gradient of W2:\", dW2)\n",
    "print(\"Gradient of b2:\", db2)\n",
    "print(\"Gradient of W1:\", dW1)\n",
    "print(\"Gradient of b1:\", db1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7376546699f060",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "反向传播"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters: [ 0.499  0.302 -0.203]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "parameters = np.array([0.5, 0.3, -0.2])\n",
    "gradients = np.array([0.1, -0.2, 0.3])\n",
    "learning_rate = 0.01\n",
    "def gradient_descent(parameters, gradients, learning_rate):\n",
    "    parameters -= learning_rate * gradients\n",
    "    return parameters\n",
    "updated_parameters = gradient_descent(parameters, gradients, learning_rate)\n",
    "print(\"Updated parameters:\", updated_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:45:50.906815Z",
     "start_time": "2024-04-11T06:45:49.275077Z"
    }
   },
   "id": "60a9e923f3044e8",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "梯度下降"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35966f69b354dab9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters: [ 0.4999  0.3002 -0.2003]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "parameters = np.array([0.5, 0.3, -0.2])\n",
    "gradients = np.array([0.1, -0.2, 0.3])\n",
    "learning_rate = 0.01\n",
    "beta = 0.9\n",
    "velocity = np.zeros_like(parameters)\n",
    "\n",
    "def momentum(parameters, gradients, velocity, learning_rate, beta):\n",
    "    velocity = beta * velocity + (1 - beta) * gradients\n",
    "    parameters -= learning_rate * velocity\n",
    "    return parameters, velocity\n",
    "\n",
    "updated_parameters, velocity = momentum(parameters, gradients, velocity, learning_rate, beta)\n",
    "print(\"Updated parameters:\", updated_parameters)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T15:47:49.277205Z",
     "start_time": "2024-04-15T15:47:48.547835Z"
    }
   },
   "id": "7e08650748638645",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "动量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f8f21c4bd4ff407"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters: [ 0.46837738  0.33162274 -0.23162276]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "parameters = np.array([0.5, 0.3, -0.2])\n",
    "gradients = np.array([0.1, -0.2, 0.3])\n",
    "learning_rate = 0.01\n",
    "beta = 0.9\n",
    "epsilon = 1e-8\n",
    "s = np.zeros_like(parameters)\n",
    "\n",
    "def rmsprop(parameters, gradients, s, learning_rate, beta, epsilon):\n",
    "    s = beta * s + (1 - beta) * (gradients ** 2)\n",
    "    parameters -= (learning_rate / np.sqrt(s + epsilon)) * gradients\n",
    "    return parameters, s\n",
    "\n",
    "updated_parameters, s = rmsprop(parameters, gradients, s, learning_rate, beta, epsilon)\n",
    "print(\"Updated parameters:\", updated_parameters)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T12:28:07.436210Z",
     "start_time": "2024-04-15T12:28:06.702576Z"
    }
   },
   "id": "32a8b2e06e666a4f",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "RMSprop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67d741a6c4c69680"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters: [ 0.49  0.31 -0.21]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "parameters = np.array([0.5, 0.3, -0.2])\n",
    "gradients = np.array([0.1, -0.2, 0.3])\n",
    "learning_rate = 0.01\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "epsilon = 1e-8\n",
    "m = np.zeros_like(parameters)\n",
    "s = np.zeros_like(parameters)\n",
    "t = 0\n",
    "\n",
    "def adam(parameters, gradients, m, s, learning_rate, beta1, beta2, epsilon, t):\n",
    "    t += 1\n",
    "    m = beta1 * m + (1 - beta1) * gradients\n",
    "    s = beta2 * s + (1 - beta2) * (gradients ** 2)\n",
    "    m_hat = m / (1 - beta1 ** t)\n",
    "    s_hat = s / (1 - beta2 ** t)\n",
    "    parameters -= (learning_rate / (np.sqrt(s_hat) + epsilon)) * m_hat\n",
    "    return parameters, m, s, t\n",
    "\n",
    "updated_parameters, m, s, t = adam(parameters, gradients, m, s, learning_rate, beta1, beta2, epsilon, t)\n",
    "print(\"Updated parameters:\", updated_parameters)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:09:23.379933Z",
     "start_time": "2024-04-15T16:09:23.359986Z"
    }
   },
   "id": "ff28dfa2bb228c14",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adam"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed814a93fdb9a9c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss with L2 regularization: 0.013800000000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 计算L2正则化项\n",
    "def l2_regularization(parameters, lambda_val):\n",
    "    l2_loss = lambda_val * np.sum(parameters ** 2)\n",
    "    return l2_loss\n",
    "\n",
    "# 计算原始损失函数（假设为均方误差）\n",
    "def original_loss(predictions, targets):\n",
    "    return np.mean((predictions - targets) ** 2)\n",
    "\n",
    "# 定义总损失函数\n",
    "def total_loss(predictions, targets, parameters, lambda_val):\n",
    "    return original_loss(predictions, targets) + l2_regularization(parameters, lambda_val)\n",
    "\n",
    "# 示例：计算带有L2正则化的总损失\n",
    "predictions = np.array([0.2, 0.4, 0.6])\n",
    "targets = np.array([0.1, 0.3, 0.5])\n",
    "parameters = np.array([0.5, 0.3, -0.2])\n",
    "lambda_val = 0.01\n",
    "\n",
    "loss_with_regularization = total_loss(predictions, targets, parameters, lambda_val)\n",
    "print(\"Total loss with L2 regularization:\", loss_with_regularization)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:17:30.031526Z",
     "start_time": "2024-04-15T16:17:30.003601Z"
    }
   },
   "id": "473133bafae66445",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "L2正则化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fc061eed02cd6fe"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped outputs: [0.25  0.625 0.    0.375 0.   ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dropout_layer(inputs, dropout_rate):\n",
    "    mask = np.random.rand(*inputs.shape) < (1 - dropout_rate)\n",
    "    dropped_inputs = inputs * mask / (1 - dropout_rate)\n",
    "    return dropped_inputs\n",
    "\n",
    "# 示例：应用Dropout到隐藏层\n",
    "hidden_layer_outputs = np.array([0.2, 0.5, 0.8, 0.3, 0.6])\n",
    "dropout_rate = 0.2\n",
    "\n",
    "dropped_outputs = dropout_layer(hidden_layer_outputs, dropout_rate)\n",
    "print(\"Dropped outputs:\", dropped_outputs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:26:13.781503Z",
     "start_time": "2024-04-15T16:26:13.753122Z"
    }
   },
   "id": "8815ff47ed1c821b",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "dropout"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "236a40018a1d9848"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.955 0.925 0.9   0.905 0.925]\n",
      "Mean cross-validation score: 0.9219999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 创建数据集\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, \n",
    "                           n_redundant=10, random_state=42)\n",
    "\n",
    "# 初始化模型\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 进行5-fold交叉验证\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean cross-validation score: {scores.mean()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T17:34:51.274199Z",
     "start_time": "2024-04-15T17:34:41.915715Z"
    }
   },
   "id": "f3898d08b4ae52b3",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "交叉验证"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9efcd80383269049"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 加载水仙花数据集\n",
    "iris = load_iris()\n",
    "X = iris.data  # 特征矩阵\n",
    "y = iris.target  # 目标变量\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 初始化 Logistic 回归模型\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上评估模型性能\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T00:45:45.807654Z",
     "start_time": "2024-04-16T00:45:44.259217Z"
    }
   },
   "id": "af2cc6c5f9eaf65e",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练集和测试集划分"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fff7328c14c3c4d4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\anacondaprojects\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 初始化 Logistic 回归模型\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 使用留一验证进行模型评估\n",
    "loo = LeaveOneOut()\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上评估模型性能\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "# 计算留一验证的平均准确率\n",
    "average_score = sum(scores) / len(scores)\n",
    "print(\"Average Score:\", average_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T01:19:55.251378Z",
     "start_time": "2024-04-16T01:19:49.623293Z"
    }
   },
   "id": "dfd278e280306f4f",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "留一验证"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2f41f804bdc1986"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.9798266666666782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 初始化决策树分类器\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# 自助法重采样和评估\n",
    "n_iterations = 1000\n",
    "scores = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    X_boot, y_boot = resample(X, y)\n",
    "\n",
    "    # 训练模型\n",
    "    model.fit(X_boot, y_boot)\n",
    "\n",
    "    # 在原始数据集上评估模型性能\n",
    "    score = model.score(X, y)\n",
    "    scores.append(score)\n",
    "\n",
    "# 计算自助法的平均准确率\n",
    "average_score = sum(scores) / len(scores)\n",
    "print(\"Average Score:\", average_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T01:39:00.492272Z",
     "start_time": "2024-04-16T01:38:57.290837Z"
    }
   },
   "id": "6966335c7f9e4cd",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "自助法"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2ee5a9a2d8e2319"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Score: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 初始化随机森林分类器\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# 使用网格搜索进行模型调优\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 输出最佳参数组合和对应的性能指标\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T01:51:46.295504Z",
     "start_time": "2024-04-16T01:51:01.831402Z"
    }
   },
   "id": "9754f31b1e3b0f79",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "网格搜索"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "625475fd46891a86"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 171}\n",
      "Best Score: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 定义参数分布\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # 树的数量在 50 到 200 之间随机选择\n",
    "    'max_depth': [None, 10, 20],  # 最大深度在 None、10 和 20 中随机选择\n",
    "    'min_samples_split': randint(2, 10)  # 最小分割样本数在 2 到 10 之间随机选择\n",
    "}\n",
    "\n",
    "# 使用随机搜索进行模型调优\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist, n_iter=100, cv=5)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# 输出最佳参数组合和对应的性能指标\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T02:45:15.315904Z",
     "start_time": "2024-04-16T02:43:13.256768Z"
    }
   },
   "id": "8099e09a5a597bf9",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "随机搜索"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15172000e9d31c5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: OrderedDict([('max_depth', 10), ('min_samples_split', 3), ('n_estimators', 188)])\n",
      "Best Score: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 定义参数搜索空间\n",
    "param_space = {\n",
    "    'n_estimators': (50, 200),\n",
    "    'max_depth': (1, 20),\n",
    "    'min_samples_split': (2, 10)\n",
    "}\n",
    "\n",
    "# 使用贝叶斯优化进行模型调优\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    search_spaces=param_space,\n",
    "    n_iter=50,  # 搜索迭代次数\n",
    "    cv=5  # 交叉验证折数\n",
    ")\n",
    "bayes_search.fit(X, y)\n",
    "\n",
    "# 输出最佳参数组合和对应的性能指标\n",
    "print(\"Best Parameters:\", bayes_search.best_params_)\n",
    "print(\"Best Score:\", bayes_search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T02:16:14.863510Z",
     "start_time": "2024-04-16T02:13:40.425995Z"
    }
   },
   "id": "dafd9576bc00ac72",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "贝叶斯优化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bb35ecf954e5cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
